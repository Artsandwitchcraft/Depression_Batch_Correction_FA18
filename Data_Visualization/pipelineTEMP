import pandas as pd
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np
import os
import pylab
from matplotlib.legend_handler import HandlerBase
import subprocess
import seaborn as sns
import numpy
import random
import math

'''
 .----------------.  .----------------.  .----------------.  .----------------.
| .--------------. || .--------------. || .--------------. || .--------------. |
| |  ________    | || |      __      | || |  _________   | || |      __      | |
| | |_   ___ `.  | || |     /  \     | || | |  _   _  |  | || |     /  \     | |
| |   | |   `. \ | || |    / /\ \    | || | |_/ | | \_|  | || |    / /\ \    | |
| |   | |    | | | || |   / ____ \   | || |     | |      | || |   / ____ \   | |
| |  _| |___.' / | || | _/ /    \ \_ | || |    _| |_     | || | _/ /    \ \_ | |
| | |________.'  | || ||____|  |____|| || |   |_____|    | || ||____|  |____|| |
| |              | || |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'  '----------------'
'''

def get_datasets():
    datasets = []
    # get all folders in a directory
    directory = 'C:/Users/Roman/Documents/Work/Depression_and_Immunology/Spring_Research/Data/'
    data_folders = [x[0] for x in os.walk(directory)][1:]

    print(data_folders)
    #print(data_folders)
    # go through each folder and get the files
    for data_folder in data_folders:
        subDir = data_folder + '/'
        data_files = [f for f in os.listdir(subDir)]
        # get gene counts
        print(data_files)
        gene_counts = subDir + [fileName for fileName in data_files if 'gene_counts' in fileName][0]
        # get meta data
        metadata = subDir + [fileName for fileName in data_files if 'metadata' in fileName][0]

        datasets.append((gene_counts, metadata, data_folder.split('/')[-1]))
    return datasets;

def get_geneCounts(gene_counts_path ,annot=None):
    # get the input files
    input_counts = gene_counts_path#"C:\\Users\\Roman\\Documents\\Work\\Depression_and_Immunology\\Data\\filteredData.csv"

    # get gene counts
    gene_counts = pd.read_csv(input_counts, index_col=0, header=0).T
    gene_counts.index = gene_counts.index.map(int)  # index is messed up for some reason

    if(not (annot == None)):
        # select only rows that appear in the annot file
        gene_counts = gene_counts.ix[annot.index.values]
        # we need to drop NaNs that were inserted from annot
    gene_counts = gene_counts.dropna()
    return gene_counts

def get_metadata(metadata_path):
    input_annot = metadata_path#"C:\\Users\\Roman\\Documents\\Work\\Depression_and_Immunology\\Scripts\\Data\\meta_data_with_paths_all_patients_final.csv"
    # get meta_data
    annot = pd.read_csv(input_annot).set_index('record_id')
    #annot = annot[annot['missing'] == False]

    return annot


'''
 .----------------.  .----------------.  .----------------.
| .--------------. || .--------------. || .--------------. |
| |   ______     | || |     ______   | || |      __      | |
| |  |_   __ \   | || |   .' ___  |  | || |     /  \     | |
| |    | |__) |  | || |  / .'   \_|  | || |    / /\ \    | |
| |    |  ___/   | || |  | |         | || |   / ____ \   | |
| |   _| |_      | || |  \ `.___.'\  | || | _/ /    \ \_ | |
| |  |_____|     | || |   `._____.'  | || ||____|  |____|| |
| |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'
'''

def plot_pca(gene_counts_path, metadata_path, folder_name,  plot_name = None):
    # run pca
    #Rscript
    #PCA_script.R - g / path / to / gene.counts - a / path / to / gene.annotation
    output_dir = 'C:/Users/Roman/Documents/Work/Depression_and_Immunology/Spring_Research/Results/' + folder_name

    try:
        os.mkdir(output_dir)
    except:
        print('it already exists okay')

    subprocess.call("Rscript C:/Users/Roman/Documents/Work/Depression_and_Immunology/Spring_Research/PCA/PCA_script.R -g "
                    + gene_counts_path + ' -a ' + metadata_path + ' -o ' + output_dir + ' -f ' + folder_name, shell=True)

'''
 .----------------.  .----------------.  .----------------.  .-----------------. .----------------.
| .--------------. || .--------------. || .--------------. || .--------------. || .--------------. |
| |  _________   | || |              | || |    _______   | || | ____  _____  | || |  _________   | |
| | |  _   _  |  | || |              | || |   /  ___  |  | || ||_   \|_   _| | || | |_   ___  |  | |
| | |_/ | | \_|  | || |    ______    | || |  |  (__ \_|  | || |  |   \ | |   | || |   | |_  \_|  | |
| |     | |      | || |   |______|   | || |   '.___`-.   | || |  | |\ \| |   | || |   |  _|  _   | |
| |    _| |_     | || |              | || |  |`\____) |  | || | _| |_\   |_  | || |  _| |___/ |  | |
| |   |_____|    | || |              | || |  |_______.'  | || ||_____|\____| | || | |_________|  | |
| |              | || |              | || |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'  '----------------'  '----------------'
'''

def plot_tsne(df,annot, perplexity, plot_name = None):

    model = TSNE(n_components=2, perplexity=perplexity, n_iter = 5000)
    model = model.fit_transform(df)



    list_color = ['k', 'k', 'k', '#11c3be', '#89f5f2', '#d7fcfa', 'r']
    list_marker = ["o", "v", "^", "x", "x", "x", "x"]
    list_lab = ['Healthy', 'Depression', 'Bipolar', 'MDD B1', 'MDD B2', 'MDD B3', 'Control Dataset']

    tsne_df = pd.DataFrame()
    tsne_df['x'] = model[:, 0]
    tsne_df['y'] = model[:, 1]
    batchValues = annot['batch'].map({0.0: 'w', 1.0:'#11c3be', 2.0:'#89f5f2', 3.0:'#d7fcfa', 4.0:'r'})

    diagnosisValues = annot['scid_diagnosis'].map({0.0: '.', 1.0:'v', 2.0:'^', 3.0:'^', 4.0:'o'})

    class MarkerHandler(HandlerBase):
        def create_artists(self, legend, tup,xdescent, ydescent,
                            width, height, fontsize,trans):
            return [plt.Line2D([width/2], [height/2.],ls="",
                           marker=tup[1],color=tup[0], transform=trans)]

    for x,y,b,d in zip(tsne_df['x'], tsne_df['y'], batchValues, diagnosisValues):
        plt.scatter(x, y, c=b, marker=d)


    plt.legend(list(zip(list_color, list_marker)), list_lab, handler_map={tuple:MarkerHandler()})

    plt.title('T-SNE Perplexity: ' + str(perplexity) + ' ' + plot_name)
    plt.savefig('t-sne_perplex_' + str(perplexity) + '_' + plot_name + '.png')
    plt.clf()
    plt.cla()
    plt.close()

'''
 .----------------.  .----------------.  .----------------.  .----------------.
| .--------------. || .--------------. || .--------------. || .--------------. |
| |  ___  ____   | || |   ______     | || |  _________   | || |  _________   | |
| | |_  ||_  _|  | || |  |_   _ \    | || | |_   ___  |  | || | |  _   _  |  | |
| |   | |_/ /    | || |    | |_) |   | || |   | |_  \_|  | || | |_/ | | \_|  | |
| |   |  __'.    | || |    |  __'.   | || |   |  _|  _   | || |     | |      | |
| |  _| |  \ \_  | || |   _| |__) |  | || |  _| |___/ |  | || |    _| |_     | |
| | |____||____| | || |  |_______/   | || | |_________|  | || |   |_____|    | |
| |              | || |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'  '----------------'
'''

def run_kBET(test_data):
    output_dir = 'C:/Users/Roman/Documents/Work/Depression_and_Immunology/Spring_Research/Results/' + test_data[2]
    try:
        os.mkdir(output_dir)
    except:
        print('it already exists okay')
        # except FileExistsError:
        # otherwise we're fine it already exists

    command = 'Rscript'
    path_to_script = "C:/Users/Roman/Documents/Work/Depression_and_Immunology/Spring_Research/kBET/kBET_script_pipeline.R"

    print('kbet THIRD ARGUMENT')
    print(test_data[2])

    args = [test_data[0], test_data[1], output_dir, test_data[2]]

    # build command
    cmd = [command, path_to_script] + args

    #NEED TO UNCOMMNE THIS
    #x = subprocess.check_output(cmd, universal_newlines=True, shell=True)

    #print(x)


    # now let's get the mean rejection rate
    kBetResultsName = output_dir + '/' + test_data[2] + '_kBET_results.csv'
    # first let's get the csv
    kBet_results = pd.read_csv(kBetResultsName)
    rejection_rate = kBet_results.ix[0, 2]
    acceptance_rate = rejection_rate#1 - rejection_rate

    return acceptance_rate
'''
 .----------------.  .----------------.  .----------------.
| .--------------. || .--------------. || .--------------. |
| |   ______     | || |     ____     | || |  ____  ____  | |
| |  |_   _ \    | || |   .'    `.   | || | |_  _||_  _| | |
| |    | |_) |   | || |  /  .--.  \  | || |   \ \  / /   | |
| |    |  __'.   | || |  | |    | |  | || |    > `' <    | |
| |   _| |__) |  | || |  \  `--'  /  | || |  _/ /'`\ \_  | |
| |  |_______/   | || |   `.____.'   | || | |____||____| | |
| |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'
'''

def boxPlot(datasets):

    # here's what we want to do
    # get the mean expression for each sample within a batch
    # each box plot should be a BATCH
    # group different types of correction together.

    sns.set(style="ticks", palette="pastel")
#    plt.set_xticklabels(rotation=45)



    # let's build the dataset
    # let's get the list of

    boxPlotData = pd.DataFrame()
    for dataset in datasets:

        gene_counts = dataset[0]
        metadata = dataset[1]
        name = dataset[2]

        # we need to iterate through each batch
        batches = np.unique(metadata['batch'])
        for batchNum in batches:
            # let's get the subset of the data
            relevent_metadata = metadata.loc[metadata['batch'] == batchNum]
            gene_counts_batch = gene_counts.ix[ relevent_metadata.index.values ]

            #print(relevent_metadata)
            #print(gene_counts_batch)

            # let's get the mean of each sample
            meanValues = gene_counts_batch.mean(axis=0)



            batch = np.ones(len(meanValues), ) * batchNum
#            meanValues['batch'] = batchNum

            print('Name is ')
            print(name)
            print('gene values numbers is ')
            print(relevent_metadata.index.values)
            #print(meanValues)
            print('batch')
            #print(batch)

#            print(meanValues)

#            batch = metadata['batch']

#            print(meanValues)
#            print(batch)
            #newDf = meanValues
            #newDf = pd.concat([meanValues, batch], axis=1)
            newDf = pd.DataFrame({'Gene Counts': meanValues, 'Batch': batch})

            print(newDf)
            newDf['name'] = name
#            newDf = newDf.rename(columns = {'0' : 'Gene Counts'})
            print(newDf)

    #        newDf.columns[0] = 'Gene Counts'
            boxPlotData= boxPlotData.append(newDf)

    #        print(box)


    print('****** BOX PLOT DATA*******(')
    print(boxPlotData)
    print('****** END BOX PLOT DATA*******(')



    sns.boxplot(x="name", y="Gene Counts",
                hue="Batch", palette=["m", "g", "r", "b"],
                data=boxPlotData)

    sns.despine(offset=10, trim=True)

    plt.show()

        # x is correction method
    # hue is batch
    # y is gene counts
        # here's what we need
        # we need a list of means for each sample for each batch
        # so [mean of each sample in batch 1], mean of each sample in batch2

        # ticks, which correction each belongs to

        #


    # get the data


        #    boxplot_data = [ gene_data.mean() for data in gene_data]
'''
    fig, ax1 = plt.subplots(figsize=(10, 6))
    fig.canvas.set_window_title('Gene data comparative box plot')
    fig.subplots_adjust(left=0.075, right=0.95, top=.9, bottom=.25)

    # add a horizontal line to the grid
    ax1.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
                   alpha=0.5)

    ax1.set_axisbelow(True)
    ax1.set_title('Comparison of Gene Counts from Different Batch Correction Methods', fontsize=20)
    ax1.set_xlabel('Gene Data', fontsize=18)
    ax1.set_ylabel('Gene Counts', fontsize=18)

    plt.boxplot(gene_data)

    numBoxes = len(gene_data)
    ax1.set_xlim(0.5, numBoxes + 0.5)
    ax1.set_xticklabels(dist_names, rotation=45, fontsize=8)
    #    plt.xticks([i for i in range(1,numBoxes+1)], dist_names)


    #    plt.boxplot(gene_data)
    plt.show()
    # Draw a nested boxplot to show bills by day and time
'''


def groupBoxPlot(datasets):
    # get the data
    gene_data = [ dataset[0].mean() for dataset in datasets]

    dist_names = [ dataset[2] for dataset in datasets]
    print(dist_names)



'''
 .----------------.  .----------------.  .----------------.
| .--------------. || .--------------. || .--------------. |
| |  ____  ____  | || | ____   ____  | || |    ______    | |
| | |_   ||   _| | || ||_  _| |_  _| | || |  .' ___  |   | |
| |   | |__| |   | || |  \ \   / /   | || | / .'   \_|   | |
| |   |  __  |   | || |   \ \ / /    | || | | |    ____  | |
| |  _| |  | |_  | || |    \ ' /     | || | \ `.___]  _| | |
| | |____||____| | || |     \_/      | || |  `._____.'   | |
| |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'
'''
def makeTables(geneCountFile, annotFile):
    # read the annotation file
    annotTable = pd.read_csv(annotFile, sep=",", header=0, index_col=0)
    # read the gene counts file
    countTable = pd.read_csv(geneCountFile, sep=",", header=0, index_col=0).T
    countTable.index = countTable.index.map(int)  # index is messed up for some reason
    return (annotTable, countTable)


def sepBatches(countTable, annotTable, batchNum):
    # get meta_data
    # both_meta_data= pd.read_csv('C:/Users/Roman/Documents/Work/Depression_and_Immunology/Scripts/gender_analysis/meta_data/second_batch_mdd_both.csv').set_index('record_id')
    batchData = annotTable.loc[annotTable['batch'] == batchNum]
    #print(countTable.T.index.values)
    #print(countTable)
    return ((countTable).ix[batchData.index.values])

#    print(male_meta_data.index.values)

    # get both genders from second batch
    # both_gender_counts = gene_counts.ix[both_meta_data.index.values]
    # print(both_gender_counts.shape)
    # get only males

    #male_gender_counts = gene_counts.ix[male_meta_data.index.values]
'''
    #print('getting stuff')
    batchone = annotTable.loc[annotTable['batch'] == batchNum]
    #print('gotttemmmmm')
    ids = batchone.index.tolist()

    countTable.columns = countTable.columns.map(int)
    print(countTable)
    genebatch = countTable.iloc[:,countTable.columns.isin(ids)]
    print(countTable)
    return genebatch
'''

def topVarience(genebatch, percentage):
    genebatch = genebatch.T
    genebatch['varience'] = genebatch.var(axis=1).tolist() # check the AXIS

    variSort = genebatch.sort_values('varience', ascending=False)
    topGenes = len(variSort.index) * percentage
    #print("My amount of gnees")
    #print(genebatch.shape[0] * percentage)
    #print('HER AMOUNT OF GENES')
    #print(topGenes)
    variSortTop = variSort.head(math.floor(topGenes)).index
    #print(variSortTop)
    return variSortTop


def getHvgs(countTableF, annotTableF, name):
    #print('GETTING HVGS FOR NAME ' + name)

    annotTable, countTable = makeTables(countTableF, annotTableF)
    if(name == 'toups_dataset_filtered_z_score_corrected'):
        print('HVGS FOR ' + name)
        print('Count table and annot table shape')
        print(countTable.shape)
        print(annotTable)
        print(annotTable['batch'])
    numBatches = np.amax(annotTable['batch'])
    #print("made it this far")
    batches = [sepBatches(countTable, annotTable, batchNum) for batchNum in range(1, numBatches + 1)]
    if(name == 'toups_dataset_filtered_z_score_corrected'):
        print('NUM BATCHES IS ' + str(numBatches))
        print('Batches shape')
        print(batches[0].shape)
        print("made it this far2")
    batchVariances = [topVarience(batch, .1) for batch in batches ]
    hvgs = batchVariances[0]
    if(name == 'toups_dataset_filtered_z_score_corrected'):
        print(batchVariances)
        print("made it this far3")
        print('HVGS are ')
        print(hvgs)
        print('*** BATCH VARIANCES length is  is actually')
    for i in range(1, len(batchVariances)):
        if (name == 'toups_dataset_filtered_z_score_corrected'):
            print('iteration is ' + str(i))
            print('hvgs is ')
            print(hvgs)
            # something might be wrong here idk??????????
        #   print(str(0) + " combined with  " + str(i))
        hvgs = hvgs.intersection(batchVariances[i])
    if(name == 'toups_dataset_filtered_z_score_corrected'):
        print('now hvgs is ')
        print(hvgs)
    allInterList = hvgs.tolist()
    with open(name + '_hvgs.txt', 'w') as f:
        for item in allInterList:
            f.write(item)
            f.write("\n")

    #print("the number of hvgs is " + str(len(allInterList)))
    return allInterList

def getIntersection(lst1, lst2):
    return list(set(lst1) & set(lst2))

def getRetained(quantativeData):
    print(quantativeData)
    beforeCorrectionHvgs = []
    newQuantativeData = []
    correction = ['z_score', 'combat', 'limma', 'pca_loading']

    for data in quantativeData:
        originalData = True
        name = data[0]
        hvgs = data[1]

        # get the original hvgs
        for c in correction:
            if(c in name):
                originalData = False

        if(originalData):
            beforeCorrectionHvgs.append((name, hvgs))

    # go through again and get the percent of HVGs retained

    print('Before correction hvgs')
    for iterObject in beforeCorrectionHvgs:
        print(iterObject[0])

    for data in quantativeData:
        name = data[0]
        hvgs = data[1]
        acceptanceRate = data[2]
        # iterate through the before correction hvgs
        for originalData in beforeCorrectionHvgs:
            originalDataName = originalData[0]
            originalDataHvgs = originalData[1]

            if(originalDataName in name):
                print('Oirignal data hvgs' + str(originalDataName))
                #print(originalDataHvgs)
                print('this HVGS name ' + str(name))
                #print(hvgs)
                divisor = len(originalDataHvgs)
                if(len(originalDataHvgs) == 0):
                    divisor = 1
                # then this is the dataset it belongs to and we should calcualte the hvg retained


                print('Name ' + name)
                print('before correction hvgs')
                print(beforeCorrectionHvgs)
                print("orignal HVGS " + str(len(originalDataHvgs)))
                print('new hvgs ' + str(len(hvgs)))
                print('intersection is ' + str(len(getIntersection(originalDataHvgs, hvgs))))
                print('divisor ' + str(len(originalDataHvgs)))
                percentRetained = (len(getIntersection(originalDataHvgs, hvgs)) / divisor) * 100.0
                print('Percent retained ' + str(percentRetained))
                print()
                newQuantativeData.append( (name, acceptanceRate, percentRetained) )
                #break

    return newQuantativeData

def kBet_plots(kBet_data):
#    x = [data[2] for data in kBet_data]
#    y = [data[1] for data in kBet_data]

    correction = ['z_score', 'combat', 'limma', 'pca_loading']
    dataset = ['toups', 'combined']
    filtration = ['unfiltered', 'filtered']
    colors = ['b','g','r','c','m','y','k']
    markers = [['|','_'],['o','+']]
#    markers = ['o','s','+','d','1', 'v','|','_']

    # create plot
    fig = plt.figure()
    ax = fig.add_subplot(1,1,1, axisbg="1.0")

    print(kBet_data)
    plot_data = [(data[2], data[1], ) for i, data in enumerate(kBet_data)]


    for data in kBet_data:
        correctionMethod= ''
        datasetUsed = 0
        filterMethod = ''
        for i, c in enumerate(correction):
            if(c in data[0]):
                correctionMethod = colors[i]
                break
        if(correctionMethod == ''): correctionMethod = colors[4]
        for i, d in enumerate(dataset):
            if(d in data[0]):
                datasetUsed = i
                break
        for i, f in enumerate(filtration):
            if(f in data[0]):
                filterMethod = markers[datasetUsed][i]
                break
        print(data)
        x = data[2]
        y = data[1]

        #color = # this will be batch correction method
        #marker = # this will be filtered or unfiltered
        # we need for dataset
        ax.scatter(x, y, c = correctionMethod, marker = filterMethod, s = 100)

    correction = ['z_score', 'combat', 'limma', 'pca_loading']
    dataset = ['toups', 'combined']
    filtration = ['unfiltered', 'filtered']
    colors = ['b','g','r','c','m','y','k']
    markers = [['|','_'],['o','+']]

#    list_color =  ['b', 'g', 'r', 'c', 'm', 'k', 'k', 'k', 'k']
#    list_marker = ["x", "x", "x", "x", 'x', "|", "_", "o", "+"]
#    list_lab = ['Z_Score', 'ComBat', 'Limma', 'PCA_Loading', 'No Correction', 'Toups Unfiltered', 'Toups Filtered', 'Combined Unfiltered', 'Combined Filtered']

    list_color =  ['b', 'g', 'r']
    list_marker = ["x", "x", "x"]
    list_lab = ['Z_Score', 'ComBat', 'Limma']

    class MarkerHandler(HandlerBase):
        def create_artists(self, legend, tup,xdescent, ydescent,
                            width, height, fontsize,trans):
            return [plt.Line2D([width/2], [height/2.],ls="",
                           marker=tup[1],color=tup[0], transform=trans)]


    plt.legend(list(zip(list_color, list_marker)), list_lab, handler_map={tuple:MarkerHandler()})
    plt.title("kBET HVG vs Acceptance Rate", fontsize = 24)
    plt.xlabel('HVG Retainment', fontsize = 18)
    plt.ylabel('Acceptance Rate', fontsize = 18)
    plt.show()


    fig, ax1 = plt.subplots(figsize=(10,6))
    fig.canvas.set_window_title('Gene Counts Comparative Box Plot')
    fig.subplots_adjust(left=0.075, right=0.95, top=0.9, bottom=0.25)

    bp = ax1.boxplot(gene_data, notch=0, sym='+', vert=1, whis=1.5)
    fig.subplots_adjust(left=0.075, right=0.95, top=0.9, bottom=0.25)

    bp = ax1.boxplot(gene_data, notch=0, sym='+', vert=1, whis=1.5)
    plt.setp(bp['boxes'], color='black')
    plt.setp(bp['whiskers'], color='black')
    plt.setp(bp['fliers'], color='red', marker='+')
    # Add a horizontal grid to the plot, but make it very light in color
    # so we can use it for reading data values but not be distracting
    ax1.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
                   alpha=0.5)
    # Hide these grid behind plot objects
    ax1.set_axisbelow(True)
    ax1.set_title('Comparison of IID Bootstrap Resampling Across Five Distributions')
    ax1.set_xlabel('Distribution')
    ax1.set_ylabel('Value')

    # Set the axes ranges and axes labels
    numBoxes = len(datasets)
    ax1.set_xlim(0.5, numBoxes + 0.5)
    top = 40
    bottom = -5


#    ax1.set_ylim(bottom, top)
#    ax1.set_xticklabels(np.repeat(randomDists, 2),
#                        rotation=45, fontsize=8)

'''
 .----------------.  .----------------.  .----------------.  .-----------------.
| .--------------. || .--------------. || .--------------. || .--------------. |
| | ____    ____ | || |      __      | || |     _____    | || | ____  _____  | |
| ||_   \  /   _|| || |     /  \     | || |    |_   _|   | || ||_   \|_   _| | |
| |  |   \/   |  | || |    / /\ \    | || |      | |     | || |  |   \ | |   | |
| |  | |\  /| |  | || |   / ____ \   | || |      | |     | || |  | |\ \| |   | |
| | _| |_\/_| |_ | || | _/ /    \ \_ | || |     _| |_    | || | _| |_\   |_  | |
| ||_____||_____|| || ||____|  |____|| || |    |_____|   | || ||_____|\____| | |
| |              | || |              | || |              | || |              | |
| '--------------' || '--------------' || '--------------' || '--------------' |
 '----------------'  '----------------'  '----------------'  '----------------'
'''
datasets = get_datasets()

genes_and_metadata = [(get_geneCounts(dataset[0]), get_metadata(dataset[1]), dataset[2], None) for dataset in datasets ]

#boxPlot(genes_and_metadata)

# GET HVGS
numHvgs = [( getHvgs(dataset[0], dataset[1], dataset[2]), dataset[2] ) for dataset in datasets[0:5]]
print('HVGS NUMEBERS ARE ')
print(numHvgs)

# RUN kBET
quantativeData = [(dataset[2], run_kBET(dataset), getHvgs(dataset[0], dataset[1], dataset[2]), ) for dataset in datasets]

# this is name, hvgs, kBet
hvgParam = [ (qData[0], qData[2] , qData[1]) for qData in quantativeData  ]
hvgsRetained = getRetained( hvgParam )
kBet_plots(hvgsRetained)

# let's get the HVGs

#run boxplots


# run plot pca
#for dataset in datasets:
#    plot_pca(dataset[0], dataset[1], dataset[2])

# run t-sne
for dataset in datasets:
    for i in range(10,51,10):
        plot_tsne(get_geneCounts(dataset[0]), get_metadata(dataset[1]), i, dataset[2])


'''
#print(x)
#subprocess.call ("C:/Users/Roman/Documents/Work/Depression_and_Immunology/Spring_Research/kBET/kBET_script_pipeline.R " + test_data[0] + test_data[1])
'''




'''
'''

#plot_tsne(gene_counts, 20)
#plot_tsne(gene_counts, 30)


